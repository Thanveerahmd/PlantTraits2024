{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":65626,"databundleVersionId":8046133,"sourceType":"competition"},{"sourceId":7526248,"sourceType":"datasetVersion","datasetId":4308295},{"sourceId":6105,"sourceType":"modelInstanceVersion","modelInstanceId":4648},{"sourceId":6113,"sourceType":"modelInstanceVersion","modelInstanceId":4618},{"sourceId":6127,"sourceType":"modelInstanceVersion","modelInstanceId":4598}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Keras logo\" width=\"100\"><br/>\nThis starter notebook is provided by the Keras team.</center>","metadata":{}},{"cell_type":"markdown","source":"# PlantTraits2024 - FGVC11 with [KerasCV](https://github.com/keras-team/keras-cv) and [Keras](https://github.com/keras-team/keras)\n\n> The objective of this competition is to uncover the biosphere, specifically to predict a broad set of 6 plant traits (e.g., leaf area, plant height) from crowd-sourced plant images and some ancillary data.\n\n<div align=\"center\">\n  <img src=\"https://i.ibb.co/C5zZ2nf/header.jpg\">\n</div>\n\nThis notebook guides you through the process of training and inferring a multi-input and multi-output Deep Learning model, specifically using the EfficientNetV2 backbone from KerasCV on the competition dataset. Specifically, this notebook uses both plant image data and ancillary tabular features to identify plant traits.\n\nFun fact: This notebook is backend-agnostic, supporting TensorFlow, PyTorch, and JAX. Utilizing KerasCV and Keras allows us to choose our preferred backend. Explore more details on [Keras](https://keras.io/keras_core/announcement/).\n\nIn this notebook, you will learn:\n\n- Dsigning a data pipeline for a multi-input and multi-output model.\n- Creating random augmentation pipeline with KerasCV.\n- Loading the data efficiently using [`tf.data`](https://www.tensorflow.org/guide/data).\n- Creating the model using KerasCV presets.\n- Training the model.\n- Inference and Submission on test data.\n\n**Note**: For a more in-depth understanding of KerasCV, refer to the [KerasCV guides](https://keras.io/guides/keras_cv/).","metadata":{}},{"cell_type":"markdown","source":"# ğŸ›  | Install Libraries  \n\nSince internet access is **disabled** during inference, we cannot install libraries in the usual `!pip install <lib_name>` manner. Instead, we need to install libraries from local files. In the following cell, we will install libraries from our local files. The installation code stays very similar - we just use the `filepath` instead of the `filename` of the library. So now the code is `!pip install <local_filepath>`. \n\n> The `filepath` of these local libraries look quite complicated, but don't be intimidated! Also `--no-deps` argument ensures that we are not installing any additional libraries.","metadata":{}},{"cell_type":"code","source":"!pip install -q /kaggle/input/kerasv3-lib-ds/keras_cv-0.8.2-py3-none-any.whl --no-deps\n!pip install -q /kaggle/input/kerasv3-lib-ds/tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --no-deps\n!pip install -q /kaggle/input/kerasv3-lib-ds/keras-3.0.4-py3-none-any.whl --no-deps","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-29T10:25:33.928323Z","iopub.execute_input":"2024-03-29T10:25:33.928909Z","iopub.status.idle":"2024-03-29T10:26:26.381471Z","shell.execute_reply.started":"2024-03-29T10:25:33.928878Z","shell.execute_reply":"2024-03-29T10:26:26.380234Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# ğŸ“š | Import Libraries ","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # you can also use tensorflow or torch\n\nimport keras_cv\nimport keras\nfrom keras import ops\nimport tensorflow as tf\n\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nimport joblib\n\nimport matplotlib.pyplot as plt ","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:26:26.383222Z","iopub.execute_input":"2024-03-29T10:26:26.383522Z","iopub.status.idle":"2024-03-29T10:26:37.714238Z","shell.execute_reply.started":"2024-03-29T10:26:26.383493Z","shell.execute_reply":"2024-03-29T10:26:37.713160Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-03-29 10:26:30.341234: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-29 10:26:30.341292: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-29 10:26:30.342712: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Library Versions","metadata":{}},{"cell_type":"code","source":"print(\"TensorFlow:\", tf.__version__)\nprint(\"Keras:\", keras.__version__)\nprint(\"KerasCV:\", keras_cv.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âš™ï¸ | Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    verbose = 1  # Verbosity\n    seed = 42  # Random seed\n    preset = \"efficientnetv2_b2_imagenet\"  # Name of pretrained classifier\n    image_size = [224, 224]  # Input image size\n    epochs = 100 # Training epochs\n    batch_size = 96  # Batch size\n    lr_mode = \"step\" # LR scheduler mode from one of \"cos\", \"step\", \"exp\"\n    drop_remainder = True  # Drop incomplete batches\n    num_classes = 6 # Number of classes in the dataset\n    num_folds = 5 # Number of folds to split the dataset\n    fold = 0 # Which fold to set as validation data\n    class_names = ['X4_mean', 'X11_mean', 'X18_mean',\n                   'X26_mean', 'X50_mean', 'X3112_mean',]\n    aux_class_names = list(map(lambda x: x.replace(\"mean\",\"sd\"), class_names))\n    num_classes = len(class_names)\n    aux_num_classes = len(aux_class_names)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:27:00.737632Z","iopub.execute_input":"2024-03-29T10:27:00.738604Z","iopub.status.idle":"2024-03-29T10:27:00.745271Z","shell.execute_reply.started":"2024-03-29T10:27:00.738568Z","shell.execute_reply":"2024-03-29T10:27:00.744305Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# â™»ï¸ | Reproducibility \nSets value for random seed to produce similar result in each run.","metadata":{}},{"cell_type":"code","source":"keras.utils.set_random_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:27:01.572353Z","iopub.execute_input":"2024-03-29T10:27:01.572906Z","iopub.status.idle":"2024-03-29T10:27:01.578850Z","shell.execute_reply.started":"2024-03-29T10:27:01.572866Z","shell.execute_reply":"2024-03-29T10:27:01.577790Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# ğŸ“ | Dataset Path ","metadata":{}},{"cell_type":"code","source":"BASE_PATH = \"/kaggle/input/planttraits2024\"","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:27:02.362434Z","iopub.execute_input":"2024-03-29T10:27:02.363094Z","iopub.status.idle":"2024-03-29T10:27:02.367201Z","shell.execute_reply.started":"2024-03-29T10:27:02.363059Z","shell.execute_reply":"2024-03-29T10:27:02.366210Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# ğŸ“– | Meta Data\n\nIn this dataset, we have information on `6` different plant traits. Here, **plant trait** refers to various characteristics or features of plants, such as leaf area or plant height. In this competition, we aim to predict the **average** of these traits, indicated as `X[*]_mean`, for each species. Additionally, in the training dataset, we are provided with the **standard deviation** of these traits, indicated by `X[*]_sd`, for each species. In our notebook, we will consider estimating the `mean` of traits as our main task and determining the `sd` as our auxiliary task. The description of each trait can be found in the table below:\n\n| trait_ID | trait_name                                                                                 |\n|----------|--------------------------------------------------------------------------------------------|\n| X4       | Stem specific density (SSD) or wood density (stem dry mass per stem fresh volume)          |\n| X11      | Leaf area per leaf dry mass (specific leaf area, SLA or 1/LMA)                              |\n| X18      | Plant height                                                                               |\n| X26      | Seed dry mass                                                                              |\n| X50      | Leaf nitrogen (N) content per leaf area                                                   |\n| X3112    | Leaf area (in the case of compound leaves: leaf, undefined if petiole in- or excluded)     |\n\n> **Note**: Even though in the `train.csv` file target labels / columns are named as `X[*]_mean`, in the `submission.csv` file they are named as `X[*]`.","metadata":{}},{"cell_type":"code","source":"# Train + Valid\ndf = pd.read_csv(f'{BASE_PATH}/train.csv')\ndf['image_path'] = f'{BASE_PATH}/train_images/'+df['id'].astype(str)+'.jpeg'\ndf.loc[:, CFG.aux_class_names] = df.loc[:, CFG.aux_class_names].fillna(-1)\ndisplay(df.head(2))\n\n# Test\ntest_df = pd.read_csv(f'{BASE_PATH}/test.csv')\ntest_df['image_path'] = f'{BASE_PATH}/test_images/'+test_df['id'].astype(str)+'.jpeg'\nFEATURE_COLS = test_df.columns[1:-1].tolist()\ndisplay(test_df.head(2))","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:27:03.162159Z","iopub.execute_input":"2024-03-29T10:27:03.162527Z","iopub.status.idle":"2024-03-29T10:27:06.060674Z","shell.execute_reply.started":"2024-03-29T10:27:03.162496Z","shell.execute_reply":"2024-03-29T10:27:06.059702Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"          id  WORLDCLIM_BIO1_annual_mean_temperature  \\\n0  192027691                               12.235703   \n1  195542235                               17.270555   \n\n   WORLDCLIM_BIO12_annual_precipitation  \\\n0                            374.466675   \n1                             90.239998   \n\n   WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month  \\\n0                                          62.524445                       \n1                                          10.351111                       \n\n   WORLDCLIM_BIO15_precipitation_seasonality  \\\n0                                  72.256844   \n1                                  38.220940   \n\n   WORLDCLIM_BIO4_temperature_seasonality  \\\n0                              773.592041   \n1                              859.193298   \n\n   WORLDCLIM_BIO7_temperature_annual_range  SOIL_bdod_0.5cm_mean_0.01_deg  \\\n0                                33.277779                            125   \n1                                40.009777                            124   \n\n   SOIL_bdod_100.200cm_mean_0.01_deg  SOIL_bdod_15.30cm_mean_0.01_deg  ...  \\\n0                                149                              136  ...   \n1                                144                              138  ...   \n\n   X26_mean  X50_mean  X3112_mean     X4_sd    X11_sd    X18_sd    X26_sd  \\\n0  1.243779  1.849375   50.216034  0.008921  1.601473  0.025441  0.153608   \n1  0.642940  1.353468  574.098472  0.003102  0.258078  0.000866  0.034630   \n\n     X50_sd   X3112_sd                                         image_path  \n0  0.279610  15.045054  /kaggle/input/planttraits2024/train_images/192...  \n1  0.010165  11.004477  /kaggle/input/planttraits2024/train_images/195...  \n\n[2 rows x 177 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>WORLDCLIM_BIO1_annual_mean_temperature</th>\n      <th>WORLDCLIM_BIO12_annual_precipitation</th>\n      <th>WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month</th>\n      <th>WORLDCLIM_BIO15_precipitation_seasonality</th>\n      <th>WORLDCLIM_BIO4_temperature_seasonality</th>\n      <th>WORLDCLIM_BIO7_temperature_annual_range</th>\n      <th>SOIL_bdod_0.5cm_mean_0.01_deg</th>\n      <th>SOIL_bdod_100.200cm_mean_0.01_deg</th>\n      <th>SOIL_bdod_15.30cm_mean_0.01_deg</th>\n      <th>...</th>\n      <th>X26_mean</th>\n      <th>X50_mean</th>\n      <th>X3112_mean</th>\n      <th>X4_sd</th>\n      <th>X11_sd</th>\n      <th>X18_sd</th>\n      <th>X26_sd</th>\n      <th>X50_sd</th>\n      <th>X3112_sd</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>192027691</td>\n      <td>12.235703</td>\n      <td>374.466675</td>\n      <td>62.524445</td>\n      <td>72.256844</td>\n      <td>773.592041</td>\n      <td>33.277779</td>\n      <td>125</td>\n      <td>149</td>\n      <td>136</td>\n      <td>...</td>\n      <td>1.243779</td>\n      <td>1.849375</td>\n      <td>50.216034</td>\n      <td>0.008921</td>\n      <td>1.601473</td>\n      <td>0.025441</td>\n      <td>0.153608</td>\n      <td>0.279610</td>\n      <td>15.045054</td>\n      <td>/kaggle/input/planttraits2024/train_images/192...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>195542235</td>\n      <td>17.270555</td>\n      <td>90.239998</td>\n      <td>10.351111</td>\n      <td>38.220940</td>\n      <td>859.193298</td>\n      <td>40.009777</td>\n      <td>124</td>\n      <td>144</td>\n      <td>138</td>\n      <td>...</td>\n      <td>0.642940</td>\n      <td>1.353468</td>\n      <td>574.098472</td>\n      <td>0.003102</td>\n      <td>0.258078</td>\n      <td>0.000866</td>\n      <td>0.034630</td>\n      <td>0.010165</td>\n      <td>11.004477</td>\n      <td>/kaggle/input/planttraits2024/train_images/195...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 177 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"          id  WORLDCLIM_BIO1_annual_mean_temperature  \\\n0  201238668                                8.086756   \n1  202310319                               10.844286   \n\n   WORLDCLIM_BIO12_annual_precipitation  \\\n0                           2246.500000   \n1                            495.871429   \n\n   WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month  \\\n0                                         127.321426                       \n1                                          28.023809                       \n\n   WORLDCLIM_BIO15_precipitation_seasonality  \\\n0                                  20.423418   \n1                                  18.738306   \n\n   WORLDCLIM_BIO4_temperature_seasonality  \\\n0                              353.381042   \n1                              786.554382   \n\n   WORLDCLIM_BIO7_temperature_annual_range  SOIL_bdod_0.5cm_mean_0.01_deg  \\\n0                                17.535713                             80   \n1                                29.292856                            130   \n\n   SOIL_bdod_100.200cm_mean_0.01_deg  SOIL_bdod_15.30cm_mean_0.01_deg  ...  \\\n0                                109                               90  ...   \n1                                155                              142  ...   \n\n   VOD_X_1997_2018_multiyear_mean_m04  VOD_X_1997_2018_multiyear_mean_m05  \\\n0                            0.389460                            0.387536   \n1                            0.300813                            0.332776   \n\n   VOD_X_1997_2018_multiyear_mean_m06  VOD_X_1997_2018_multiyear_mean_m07  \\\n0                            0.374910                            0.363712   \n1                            0.314386                            0.291168   \n\n   VOD_X_1997_2018_multiyear_mean_m08  VOD_X_1997_2018_multiyear_mean_m09  \\\n0                            0.364623                            0.379435   \n1                            0.280947                            0.277623   \n\n   VOD_X_1997_2018_multiyear_mean_m10  VOD_X_1997_2018_multiyear_mean_m11  \\\n0                            0.388294                            0.398887   \n1                            0.276503                            0.271212   \n\n   VOD_X_1997_2018_multiyear_mean_m12  \\\n0                            0.397853   \n1                            0.272672   \n\n                                          image_path  \n0  /kaggle/input/planttraits2024/test_images/2012...  \n1  /kaggle/input/planttraits2024/test_images/2023...  \n\n[2 rows x 165 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>WORLDCLIM_BIO1_annual_mean_temperature</th>\n      <th>WORLDCLIM_BIO12_annual_precipitation</th>\n      <th>WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month</th>\n      <th>WORLDCLIM_BIO15_precipitation_seasonality</th>\n      <th>WORLDCLIM_BIO4_temperature_seasonality</th>\n      <th>WORLDCLIM_BIO7_temperature_annual_range</th>\n      <th>SOIL_bdod_0.5cm_mean_0.01_deg</th>\n      <th>SOIL_bdod_100.200cm_mean_0.01_deg</th>\n      <th>SOIL_bdod_15.30cm_mean_0.01_deg</th>\n      <th>...</th>\n      <th>VOD_X_1997_2018_multiyear_mean_m04</th>\n      <th>VOD_X_1997_2018_multiyear_mean_m05</th>\n      <th>VOD_X_1997_2018_multiyear_mean_m06</th>\n      <th>VOD_X_1997_2018_multiyear_mean_m07</th>\n      <th>VOD_X_1997_2018_multiyear_mean_m08</th>\n      <th>VOD_X_1997_2018_multiyear_mean_m09</th>\n      <th>VOD_X_1997_2018_multiyear_mean_m10</th>\n      <th>VOD_X_1997_2018_multiyear_mean_m11</th>\n      <th>VOD_X_1997_2018_multiyear_mean_m12</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201238668</td>\n      <td>8.086756</td>\n      <td>2246.500000</td>\n      <td>127.321426</td>\n      <td>20.423418</td>\n      <td>353.381042</td>\n      <td>17.535713</td>\n      <td>80</td>\n      <td>109</td>\n      <td>90</td>\n      <td>...</td>\n      <td>0.389460</td>\n      <td>0.387536</td>\n      <td>0.374910</td>\n      <td>0.363712</td>\n      <td>0.364623</td>\n      <td>0.379435</td>\n      <td>0.388294</td>\n      <td>0.398887</td>\n      <td>0.397853</td>\n      <td>/kaggle/input/planttraits2024/test_images/2012...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>202310319</td>\n      <td>10.844286</td>\n      <td>495.871429</td>\n      <td>28.023809</td>\n      <td>18.738306</td>\n      <td>786.554382</td>\n      <td>29.292856</td>\n      <td>130</td>\n      <td>155</td>\n      <td>142</td>\n      <td>...</td>\n      <td>0.300813</td>\n      <td>0.332776</td>\n      <td>0.314386</td>\n      <td>0.291168</td>\n      <td>0.280947</td>\n      <td>0.277623</td>\n      <td>0.276503</td>\n      <td>0.271212</td>\n      <td>0.272672</td>\n      <td>/kaggle/input/planttraits2024/test_images/2023...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 165 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# ğŸš | DataLoader\n\nThis DataLoader simultaneously processes JPEG `images` and tabular `features` as inputs. It also handles labels for both main and auxiliary tasks. Then, it applies augmentations such as `flip`, `rotation`, `brightness`, etc. Unlike typical augmentations, these augmentations are applied to a batch, which speeds up training and reduces CPU bottleneck.","metadata":{}},{"cell_type":"code","source":"def build_augmenter():\n    # Define augmentations\n    aug_layers = [\n        keras_cv.layers.RandomBrightness(factor=0.1, value_range=(0, 1)),\n        keras_cv.layers.RandomContrast(factor=0.1, value_range=(0, 1)),\n        keras_cv.layers.RandomSaturation(factor=(0.45, 0.55)),\n        keras_cv.layers.RandomHue(factor=0.1, value_range=(0, 1)),\n        keras_cv.layers.RandomCutout(height_factor=(0.06, 0.15), width_factor=(0.06, 0.15)),\n        keras_cv.layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n        keras_cv.layers.RandomZoom(height_factor=(0.05, 0.15)),\n        keras_cv.layers.RandomRotation(factor=(0.01, 0.05)),\n    ]\n    \n    # Apply augmentations to random samples\n    aug_layers = [keras_cv.layers.RandomApply(x, rate=0.5) for x in aug_layers]\n    \n    # Build augmentation layer\n    augmenter = keras_cv.layers.Augmenter(aug_layers)\n\n    # Apply augmentations\n    def augment(inp, label):\n        images = inp[\"images\"]\n        aug_data = {\"images\": images}\n        aug_data = augmenter(aug_data)\n        inp[\"images\"] = aug_data[\"images\"]\n        return inp, label\n    return augment\n\n\ndef build_decoder(with_labels=True, target_size=CFG.image_size):\n    def decode_image(inp):\n        path = inp[\"images\"]\n        \n        # Read jpeg image\n        file_bytes = tf.io.read_file(path)\n        image = tf.io.decode_jpeg(file_bytes)\n        \n        # Resize\n        image = tf.image.resize(image, size=target_size, method=\"area\")\n        \n        # Rescale image\n        image = tf.cast(image, tf.float32)\n        image /= 255.0\n        \n        # Reshape\n        image = tf.reshape(image, [*target_size, 3])\n        \n        inp[\"images\"] = image\n        return inp\n\n    def decode_label(label, num_classes):\n        label = tf.cast(label, tf.float32)\n        label = tf.reshape(label, [num_classes])\n        return label\n\n    def decode_with_labels(inp, labels=None):\n        inp = decode_image(inp)\n        label = decode_label(labels[0], CFG.num_classes)\n        aux_label = decode_label(labels[1], CFG.aux_num_classes)\n        return (inp, (label, aux_label))\n\n    return decode_with_labels if with_labels else decode_image\n\n\ndef build_dataset(\n    paths,\n    features,\n    labels=None,\n    aux_labels=None,\n    batch_size=32,\n    cache=True,\n    decode_fn=None,\n    augment_fn=None,\n    augment=False,\n    repeat=True,\n    shuffle=1024,\n    cache_dir=\"\",\n    drop_remainder=False,\n):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n\n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None or aux_labels is not None)\n\n    if augment_fn is None:\n        augment_fn = build_augmenter()\n\n    AUTO = tf.data.experimental.AUTOTUNE\n\n    inp = {\"images\": paths, \"features\": features}\n    slices = (inp, (labels, aux_labels)) if labels is not None else inp\n\n    ds = tf.data.Dataset.from_tensor_slices(slices)\n    ds = ds.map(decode_fn, num_parallel_calls=AUTO)\n    ds = ds.cache(cache_dir) if cache else ds\n    ds = ds.repeat() if repeat else ds\n    if shuffle:\n        ds = ds.shuffle(shuffle, seed=CFG.seed)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n    ds = ds.map(augment_fn, num_parallel_calls=AUTO) if augment else ds\n    ds = ds.prefetch(AUTO)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:27:06.062671Z","iopub.execute_input":"2024-03-29T10:27:06.062990Z","iopub.status.idle":"2024-03-29T10:27:06.082428Z","shell.execute_reply.started":"2024-03-29T10:27:06.062964Z","shell.execute_reply":"2024-03-29T10:27:06.081420Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## ğŸ”ª | Data Split\n\nIn the following code, we will split the data into `5` stratified folds. It first creates bins based on `6` plant traits distributions and combines them into a final bin column. Then, it uses this bin for balancing similar traits distributions across all folds.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=42)\n\n# Create separate bin for each traits\nfor i, trait in enumerate(CFG.class_names):\n\n    # Determine the bin edges dynamically based on the distribution of traits\n    bin_edges = np.percentile(df[trait], np.linspace(0, 100, CFG.num_folds + 1))\n    df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n\n# Concatenate the bins into a final bin\ndf[\"final_bin\"] = (\n    df[[f\"bin_{i}\" for i in range(len(CFG.class_names))]]\n    .astype(str)\n    .agg(\"\".join, axis=1)\n)\n\n# Perform the stratified split using final bin\ndf = df.reset_index(drop=True)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(df, df[\"final_bin\"])):\n    df.loc[valid_idx, \"fold\"] = fold","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:27:08.087172Z","iopub.execute_input":"2024-03-29T10:27:08.087518Z","iopub.status.idle":"2024-03-29T10:27:09.965720Z","shell.execute_reply.started":"2024-03-29T10:27:08.087489Z","shell.execute_reply":"2024-03-29T10:27:09.964753Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Build Train & Valid Dataset\n\nIn the following code, we'll create **train** and **valid** data loaders. When dealing with tabular features (ancillary data), there are typically several processing steps involved. In this competition, however, the tabular data consists only of continuous, non-categorical features, which simplifies our task. Thus, we don't need to encode any categories. Before passing the tabular `features` to the model, we apply standard normalization using `StandardScaler`. This normalization step ensures that features have consistent scales, which is crucial for optimal performance of `Dense` or `Linear` layers. Readers are encouraged to experiment with advanced feature processing with raw features.\n\n> **Note**: The data loader processes (`image`, `label`) for the main task, and (`feature`, `aux_label`) for the auxiliary task.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Sample from full data\nsample_df = df.copy()\ntrain_df = sample_df[sample_df.fold != CFG.fold]\nvalid_df = sample_df[sample_df.fold == CFG.fold]\nprint(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n\n# Normalize features\nscaler = StandardScaler()\ntrain_features = scaler.fit_transform(train_df[FEATURE_COLS].values)\nvalid_features = scaler.transform(valid_df[FEATURE_COLS].values)\n\n# Train\ntrain_paths = train_df.image_path.values\ntrain_labels = train_df[CFG.class_names].values\ntrain_aux_labels = train_df[CFG.aux_class_names].values\ntrain_ds = build_dataset(train_paths, train_features, train_labels, train_aux_labels,\n                         batch_size=CFG.batch_size,\n                         repeat=True, shuffle=True, augment=True, cache=False)\n\n# Valid\nvalid_paths = valid_df.image_path.values\nvalid_labels = valid_df[CFG.class_names].values\nvalid_aux_labels = valid_df[CFG.aux_class_names].values\nvalid_ds = build_dataset(valid_paths, valid_features, valid_labels, valid_aux_labels,\n                         batch_size=CFG.batch_size,\n                         repeat=False, shuffle=False, augment=False, cache=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:27:09.967321Z","iopub.execute_input":"2024-03-29T10:27:09.967912Z","iopub.status.idle":"2024-03-29T10:27:13.636776Z","shell.execute_reply.started":"2024-03-29T10:27:09.967884Z","shell.execute_reply":"2024-03-29T10:27:13.635781Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"# Num Train: 44391 | Num Valid: 11098\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Dataset Check\n\nLet's visualize some samples and their associated labels from the dataset.","metadata":{}},{"cell_type":"code","source":"inps, tars = next(iter(train_ds))\nimgs = inps[\"images\"]\nnum_imgs, num_cols = 8, 4\n\nplt.figure(figsize=(4 * num_cols, num_imgs // num_cols * 5))\nfor i, (img, tar) in enumerate(zip(imgs[:num_imgs], tars[0][:num_imgs])):\n    plt.subplot(num_imgs // num_cols, num_cols, i + 1)\n    img = img. numpy()\n    tar = tar.numpy()\n    \n    img = (img - img.min()) / (img.max() + 1e-4)\n\n    formatted_tar = \"\\n\".join(\n        [\n            \", \".join(\n                f\"{name.replace('_mean','')}: {val:.2f}\"\n                for name, val in zip(CFG.class_names[j : j + 3], tar[j : j + 3])\n            )\n            for j in range(0, len(CFG.class_names), 3)\n        ]\n    )\n\n    plt.imshow(img)\n    plt.title(f\"[{formatted_tar}]\")\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-29T10:27:13.638217Z","iopub.execute_input":"2024-03-29T10:27:13.638578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ğŸ” | Loss & Metric\n\nThe evaluation metric in this competition is $R^2$ (coefficient of determination) is defined as:\n\n$$\n\\begin{equation}\n\\begin{aligned}\nR^2 &= 1 - \\frac{SS_{\\text{residual}}}{SS_{\\text{total}}} \\\\\n    &= 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\n\\end{aligned}\n\\end{equation}\n$$\n\nWhere:\n- $SS$ is sum of squares.\n- $n$ is the number of samples.\n- $y_i$ is the true value of the $i^{th}$ sample.\n- $\\hat{y}_i$ is the predicted value of the $i^{th}$ sample.\n- $\\bar{y}$ is the mean of the true values.\n\nIn our notebook, we will use $\\frac{SS_{residual}}{SS_{total}}$ as loss function and use $R^2$ as evaluation metric. For auxiliary task, where some samples don't have target labels, we will exclude them from the loss calculation using `use_mask` argument.","metadata":{}},{"cell_type":"code","source":"from keras import ops\n\nclass R2Loss(keras.losses.Loss):\n    def __init__(self, use_mask=False, name=\"r2_loss\"):\n        super().__init__(name=name)\n        self.use_mask = use_mask\n\n    def call(self, y_true, y_pred):\n        if self.use_mask:\n            mask = (y_true != -1)\n            y_true = ops.where(mask, y_true, 0.0)\n            y_pred = ops.where(mask, y_pred, 0.0)\n        SS_res = ops.sum(ops.square(y_true - y_pred), axis=0)  # (B, C) -> (C,)\n        SS_tot = ops.sum(ops.square(y_true - ops.mean(y_true, axis=0)), axis=0)  # (B, C) -> (C,)\n        r2_loss = SS_res / (SS_tot + 1e-6)  # (C,)\n        return ops.mean(r2_loss)  # ()\n    \nclass R2Metric(keras.metrics.Metric):\n    def __init__(self, name=\"r2\", **kwargs):\n        super(R2Metric, self).__init__(name=name, **kwargs)\n        self.SS_res = self.add_weight(name='SS_res', shape=(6,), initializer='zeros')\n        self.SS_tot = self.add_weight(name='SS_tot', shape=(6,) ,initializer='zeros')\n        self.num_samples = self.add_weight(name='num_samples', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        SS_res = ops.sum(ops.square(y_true - y_pred), axis=0)\n        SS_tot = ops.sum(ops.square(y_true - ops.mean(y_true, axis=0)), axis=0)\n        self.SS_res.assign_add(SS_res)\n        self.SS_tot.assign_add(SS_tot)\n        self.num_samples.assign_add(ops.cast(ops.shape(y_true)[0], \"float32\"))\n\n    def result(self):\n        r2 = 1 - self.SS_res / (self.SS_tot + 1e-6)\n        return ops.mean(r2)\n\n    def reset_states(self):\n        self.total_SS_res.assign(0)\n        self.total_SS_tot.assign(0)\n        self.num_samples.assign(0)","metadata":{"execution":{"iopub.execute_input":"2024-03-29T10:27:19.903414Z","iopub.status.idle":"2024-03-29T10:27:19.920080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ğŸ¤– | Modeling\n\nIn this notebook, we utilize the `EfficientNetV2 B2` backbone from KerasCV's pretrained models to extract features from images and `Dense` layers to extract features from tabular data. We then employ two `Dense` layers as our final layers (heads): one without activation (for the **main task**) and the other with `relu` activation (for the **auxiliary task**). We choose `relu` for the auxiliary task because we are estimating the **standard deviation** of plant traits, which is always **positive**. This is similar to how we use `sigmoid` activation when the target variable ranges between `0` and `1`.\n\nTo explore other backbones, simply modify the `preset` in the `CFG` (config). A list of available pretrained backbones can be found on the [KerasCV website](https://keras.io/api/keras_cv/models/).\n\n## Model Architecture Overview\n\n- Image input â†’ Main Task â†’ Head\n- Tabular input â†’ Auxiliary Task â†’ Aux Head\n\n> **Note:** We assign more weight to the `head` than the `aux_head` since it is our main task, and our evaluation metric is calculated for the `head`, not the `aux_head`.\"","metadata":{}},{"cell_type":"markdown","source":"This yolobackbone go below to mobilenet","metadata":{}},{"cell_type":"code","source":"# Define input layers\nimg_input = keras.Input(shape=(*CFG.image_size, 3), name=\"images\")\nfeat_input = keras.Input(shape=(len(FEATURE_COLS),), name=\"features\")\n\n# Branch for image input\nbackbone = keras_cv.models.YOLOV8Backbone.from_preset(\"yolo_v8_xs_backbone_coco\")\nx1 = backbone(img_input)\nx1 = keras.layers.GlobalAveragePooling2D()(x1)\nx1 = keras.layers.Dropout(0.2)(x1)\n\n# Branch for tabular/feature input\nx2 = keras.layers.Dense(326, activation=\"selu\")(feat_input)\nx2 = keras.layers.Dense(64, activation=\"selu\")(x2)\nx2 = keras.layers.Dropout(0.1)(x2)\n\n# Concatenate both branches\nconcat = keras.layers.Concatenate()([x1, x2])\n\n# Output layer\nout1 = keras.layers.Dense(CFG.num_classes, activation=None, name=\"head\")(concat)\nout2 = keras.layers.Dense(CFG.aux_num_classes, activation=\"relu\", name=\"aux_head\")(concat)\nout = {\"head\": out1, \"aux_head\":out2}\n\n# Build model\nmodel = keras.models.Model([img_input, feat_input], out)\n\n# Compile the model\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n    loss={\n        \"head\": R2Loss(use_mask=False),\n        \"aux_head\": R2Loss(use_mask=True), # use_mask to ignore `NaN` auxiliary labels\n    },\n    loss_weights={\"head\": 1.0, \"aux_head\": 0.3},  # more weight to main task\n    metrics={\"head\": R2Metric()}, # evaluation metric only on main task\n)\n\n# Model Summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:27:46.917646Z","iopub.execute_input":"2024-03-29T10:27:46.918534Z","iopub.status.idle":"2024-03-29T10:27:50.577059Z","shell.execute_reply.started":"2024-03-29T10:27:46.918498Z","shell.execute_reply":"2024-03-29T10:27:50.576137Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Attaching 'config.json' from model 'keras/yolov8/keras/yolo_v8_xs_backbone_coco/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/yolov8/keras/yolo_v8_xs_backbone_coco/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/yolov8/keras/yolo_v8_xs_backbone_coco/2' to your Kaggle notebook...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mParam #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ images (\u001b[38;5;33mInputLayer\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚       \u001b[38;5;34m0\u001b[0m â”‚ -                    â”‚\nâ”‚                     â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ features            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m163\u001b[0m)       â”‚       \u001b[38;5;34m0\u001b[0m â”‚ -                    â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ yolov8_backbone     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m) â”‚ \u001b[38;5;34m1,277,â€¦\u001b[0m â”‚ images[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\nâ”‚ (\u001b[38;5;33mYOLOV8Backbone\u001b[0m)    â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m326\u001b[0m)       â”‚  \u001b[38;5;34m53,464\u001b[0m â”‚ features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚       \u001b[38;5;34m0\u001b[0m â”‚ yolov8_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚  \u001b[38;5;34m20,928\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚       \u001b[38;5;34m0\u001b[0m â”‚ global_average_poolâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚       \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate_5       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)       â”‚       \u001b[38;5;34m0\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       â”‚\nâ”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚         â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ aux_head (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         â”‚   \u001b[38;5;34m1,926\u001b[0m â”‚ concatenate_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ head (\u001b[38;5;33mDense\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         â”‚   \u001b[38;5;34m1,926\u001b[0m â”‚ concatenate_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\"> Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to         </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ images (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                    â”‚\nâ”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ features            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">163</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ yolov8_backbone     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1,277,â€¦</span> â”‚ images[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">YOLOV8Backbone</span>)    â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">326</span>)       â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">53,464</span> â”‚ features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ yolov8_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">20,928</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_poolâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate_5       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚         â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ aux_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">1,926</span> â”‚ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">1,926</span> â”‚ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,355,924\u001b[0m (5.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,355,924</span> (5.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,350,900\u001b[0m (5.15 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,350,900</span> (5.15 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,024\u001b[0m (19.62 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,024</span> (19.62 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Plot Model\n\nAs our model is multi-input and multi-output, it is difficult to understand what is going on inside the architecture. That is where `plot_model` from **Keras** can be very handy. We can draw the overall architecture, making it easier to design or recheck our architecture.","metadata":{}},{"cell_type":"code","source":"keras.utils.plot_model(model, show_shapes=True)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-03-29T10:27:55.602208Z","iopub.execute_input":"2024-03-29T10:27:55.602847Z","iopub.status.idle":"2024-03-29T10:27:56.035636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define input layers\nimg_input = keras.Input(shape=(*CFG.image_size, 3), name=\"images\")\nfeat_input = keras.Input(shape=(len(FEATURE_COLS),), name=\"features\")\n\n# Branch for image input\nbackbone = keras_cv.models.MobileNetV3Backbone.from_preset(\"mobilenet_v3_large_imagenet\",)\nx1 = backbone(img_input)\nx1 = keras.layers.GlobalAveragePooling2D()(x1)\nx1 = keras.layers.Dropout(0.2)(x1)\n\n# Branch for tabular/feature input\nx2 = keras.layers.Dense(326, activation=\"selu\")(feat_input)\nx2 = keras.layers.Dense(64, activation=\"selu\")(x2)\nx2 = keras.layers.Dropout(0.1)(x2)\n\n# Concatenate both branches\nconcat = keras.layers.Concatenate()([x1, x2])\n\n# Output layer\nout1 = keras.layers.Dense(CFG.num_classes, activation=None, name=\"head\")(concat)\nout2 = keras.layers.Dense(CFG.aux_num_classes, activation=\"relu\", name=\"aux_head\")(concat)\nout = {\"head\": out1, \"aux_head\":out2}\n\n# Build model\nmodel = keras.models.Model([img_input, feat_input], out)\n\n# Compile the model\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n    loss={\n        \"head\": R2Loss(use_mask=False),\n        \"aux_head\": R2Loss(use_mask=True), # use_mask to ignore `NaN` auxiliary labels\n    },\n    loss_weights={\"head\": 1.0, \"aux_head\": 0.3},  # more weight to main task\n    metrics={\"head\": R2Metric()}, # evaluation metric only on main task\n)\n\n# Model Summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:36:14.073224Z","iopub.execute_input":"2024-03-28T17:36:14.073537Z","iopub.status.idle":"2024-03-28T17:36:20.535945Z","shell.execute_reply.started":"2024-03-28T17:36:14.073510Z","shell.execute_reply":"2024-03-28T17:36:20.534900Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Attaching 'config.json' from model 'keras/mobilenetv3/keras/mobilenet_v3_large_imagenet/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/mobilenetv3/keras/mobilenet_v3_large_imagenet/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/mobilenetv3/keras/mobilenet_v3_large_imagenet/2' to your Kaggle notebook...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mParam #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ images (\u001b[38;5;33mInputLayer\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚       \u001b[38;5;34m0\u001b[0m â”‚ -                    â”‚\nâ”‚                     â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ features            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m163\u001b[0m)       â”‚       \u001b[38;5;34m0\u001b[0m â”‚ -                    â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ mobile_net_v3_largâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) â”‚ \u001b[38;5;34m2,996,â€¦\u001b[0m â”‚ images[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\nâ”‚ (\u001b[38;5;33mMobileNetV3Backboâ€¦\u001b[0m â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m326\u001b[0m)       â”‚  \u001b[38;5;34m53,464\u001b[0m â”‚ features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)       â”‚       \u001b[38;5;34m0\u001b[0m â”‚ mobile_net_v3_largeâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚  \u001b[38;5;34m20,928\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)       â”‚       \u001b[38;5;34m0\u001b[0m â”‚ global_average_poolâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚       \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      â”‚       \u001b[38;5;34m0\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       â”‚\nâ”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚         â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ aux_head (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         â”‚   \u001b[38;5;34m6,150\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ head (\u001b[38;5;33mDense\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         â”‚   \u001b[38;5;34m6,150\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\"> Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to         </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ images (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                    â”‚\nâ”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ features            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">163</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ mobile_net_v3_largâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2,996,â€¦</span> â”‚ images[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MobileNetV3Backboâ€¦</span> â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">326</span>)       â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">53,464</span> â”‚ features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ mobile_net_v3_largeâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚         â”‚                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">20,928</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_poolâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚         â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ aux_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">6,150</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">6,150</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,083,044\u001b[0m (11.76 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,083,044</span> (11.76 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,058,644\u001b[0m (11.67 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,058,644</span> (11.67 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,400\u001b[0m (95.31 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,400</span> (95.31 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# âš“ | LR Schedule\n\nA well-structured learning rate schedule is essential for efficient model training, ensuring optimal convergence and avoiding issues such as overshooting or stagnation.","metadata":{}},{"cell_type":"code","source":"import math\n\ndef get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n    lr_start, lr_max, lr_min = 5e-5, 8e-6 * batch_size, 1e-5\n    lr_ramp_ep, lr_sus_ep, lr_decay = 3, 0, 0.75\n\n    def lrfn(epoch):  # Learning rate update function\n        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n        elif mode == 'cos':\n            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index / decay_total_epochs\n            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n        return lr\n\n    if plot:  # Plot lr curve if plot is True\n        plt.figure(figsize=(10, 5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('lr')\n        plt.title('LR Scheduler')\n        plt.show()\n\n    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-29T10:28:03.583369Z","iopub.execute_input":"2024-03-29T10:28:03.584019Z","iopub.status.idle":"2024-03-29T10:28:03.594442Z","shell.execute_reply.started":"2024-03-29T10:28:03.583981Z","shell.execute_reply":"2024-03-29T10:28:03.593471Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"lr_cb = get_lr_callback(CFG.batch_size, mode=CFG.lr_mode, plot=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:28:04.052989Z","iopub.execute_input":"2024-03-29T10:28:04.053633Z","iopub.status.idle":"2024-03-29T10:28:04.260194Z","shell.execute_reply.started":"2024-03-29T10:28:04.053603Z","shell.execute_reply":"2024-03-29T10:28:04.259335Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# ğŸ’¾ | Model Checkpoint","metadata":{}},{"cell_type":"code","source":"ckpt_cb = keras.callbacks.ModelCheckpoint(\n    \"best_model.keras\",\n    monitor=\"val_head_r2\",\n    save_best_only=True,\n    save_weights_only=False,\n    mode=\"max\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:28:08.628348Z","iopub.execute_input":"2024-03-29T10:28:08.628750Z","iopub.status.idle":"2024-03-29T10:28:08.633564Z","shell.execute_reply.started":"2024-03-29T10:28:08.628702Z","shell.execute_reply":"2024-03-29T10:28:08.632540Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# ğŸš‚ | Training","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    epochs=50,\n    callbacks=[lr_cb, ckpt_cb],\n    steps_per_epoch=len(train_df) // CFG.batch_size,\n    validation_data=valid_ds,\n    verbose=CFG.verbose,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:28:17.623257Z","iopub.execute_input":"2024-03-29T10:28:17.623633Z","iopub.status.idle":"2024-03-29T15:40:54.518649Z","shell.execute_reply.started":"2024-03-29T10:28:17.623603Z","shell.execute_reply":"2024-03-29T15:40:54.517750Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m  2/462\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - head_r2: -1.0084 - loss: 3.3697   ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1711708139.305477      96 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 996ms/step - head_r2: -0.2445 - loss: 2.1879 - val_head_r2: -0.0025 - val_loss: 1.5027 - learning_rate: 5.0000e-05\nEpoch 2/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 850ms/step - head_r2: -0.0548 - loss: 1.5518 - val_head_r2: 0.0146 - val_loss: 1.3585 - learning_rate: 2.8933e-04\nEpoch 3/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 841ms/step - head_r2: -0.0191 - loss: 1.3577 - val_head_r2: -0.0138 - val_loss: 2.0851 - learning_rate: 5.2867e-04\nEpoch 4/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 849ms/step - head_r2: -0.0033 - loss: 1.2865 - val_head_r2: 0.0258 - val_loss: 1.2881 - learning_rate: 7.6800e-04\nEpoch 5/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 865ms/step - head_r2: 0.0092 - loss: 1.2512 - val_head_r2: 0.0226 - val_loss: 1.3052 - learning_rate: 7.6800e-04\nEpoch 6/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 824ms/step - head_r2: 0.0145 - loss: 1.2353 - val_head_r2: 0.0323 - val_loss: 1.2579 - learning_rate: 5.7600e-04\nEpoch 7/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 824ms/step - head_r2: 0.0175 - loss: 1.2251 - val_head_r2: 0.0352 - val_loss: 1.2477 - learning_rate: 5.7600e-04\nEpoch 8/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 786ms/step - head_r2: 0.0212 - loss: 1.2163 - val_head_r2: 0.0349 - val_loss: 1.2994 - learning_rate: 4.3200e-04\nEpoch 9/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 831ms/step - head_r2: 0.0220 - loss: 1.2097 - val_head_r2: 0.0068 - val_loss: 1.5168 - learning_rate: 4.3200e-04\nEpoch 10/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 802ms/step - head_r2: 0.0256 - loss: 1.1991 - val_head_r2: 0.0346 - val_loss: 1.3668 - learning_rate: 3.2400e-04\nEpoch 11/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 777ms/step - head_r2: 0.0270 - loss: 1.1956 - val_head_r2: 0.0409 - val_loss: 1.2173 - learning_rate: 3.2400e-04\nEpoch 12/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 828ms/step - head_r2: 0.0296 - loss: 1.1866 - val_head_r2: -0.0253 - val_loss: 1.7650 - learning_rate: 2.4300e-04\nEpoch 13/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 772ms/step - head_r2: 0.0317 - loss: 1.1808 - val_head_r2: 0.0443 - val_loss: 1.2461 - learning_rate: 2.4300e-04\nEpoch 14/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 828ms/step - head_r2: 0.0344 - loss: 1.1734 - val_head_r2: 0.0520 - val_loss: 1.2034 - learning_rate: 1.8225e-04\nEpoch 15/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 801ms/step - head_r2: 0.0369 - loss: 1.1690 - val_head_r2: 0.0452 - val_loss: 1.2218 - learning_rate: 1.8225e-04\nEpoch 16/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 776ms/step - head_r2: 0.0394 - loss: 1.1617 - val_head_r2: 0.0490 - val_loss: 1.2471 - learning_rate: 1.3669e-04\nEpoch 17/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 826ms/step - head_r2: 0.0417 - loss: 1.1555 - val_head_r2: 0.0507 - val_loss: 1.1952 - learning_rate: 1.3669e-04\nEpoch 18/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 798ms/step - head_r2: 0.0451 - loss: 1.1497 - val_head_r2: 0.0481 - val_loss: 1.1890 - learning_rate: 1.0252e-04\nEpoch 19/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 799ms/step - head_r2: 0.0487 - loss: 1.1412 - val_head_r2: 0.0507 - val_loss: 1.2328 - learning_rate: 1.0252e-04\nEpoch 20/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 788ms/step - head_r2: 0.0520 - loss: 1.1340 - val_head_r2: 0.0503 - val_loss: 1.2022 - learning_rate: 7.6887e-05\nEpoch 21/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 758ms/step - head_r2: 0.0543 - loss: 1.1297 - val_head_r2: 0.0399 - val_loss: 1.1957 - learning_rate: 7.6887e-05\nEpoch 22/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 810ms/step - head_r2: 0.0592 - loss: 1.1197 - val_head_r2: 0.0382 - val_loss: 1.1987 - learning_rate: 5.7665e-05\nEpoch 23/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 795ms/step - head_r2: 0.0617 - loss: 1.1155 - val_head_r2: 0.0286 - val_loss: 1.2253 - learning_rate: 5.7665e-05\nEpoch 24/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 789ms/step - head_r2: 0.0654 - loss: 1.1100 - val_head_r2: 0.0390 - val_loss: 1.2051 - learning_rate: 4.3249e-05\nEpoch 25/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 794ms/step - head_r2: 0.0689 - loss: 1.1033 - val_head_r2: 0.0399 - val_loss: 1.2005 - learning_rate: 4.3249e-05\nEpoch 26/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 789ms/step - head_r2: 0.0734 - loss: 1.0956 - val_head_r2: 0.0254 - val_loss: 1.2149 - learning_rate: 3.2437e-05\nEpoch 27/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 791ms/step - head_r2: 0.0791 - loss: 1.0877 - val_head_r2: 0.0279 - val_loss: 1.2113 - learning_rate: 3.2437e-05\nEpoch 28/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 801ms/step - head_r2: 0.0774 - loss: 1.0870 - val_head_r2: 0.0226 - val_loss: 1.2180 - learning_rate: 2.4327e-05\nEpoch 29/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 795ms/step - head_r2: 0.0826 - loss: 1.0823 - val_head_r2: 0.0249 - val_loss: 1.2140 - learning_rate: 2.4327e-05\nEpoch 30/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 788ms/step - head_r2: 0.0848 - loss: 1.0766 - val_head_r2: 0.0212 - val_loss: 1.2174 - learning_rate: 1.8246e-05\nEpoch 31/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 787ms/step - head_r2: 0.0862 - loss: 1.0743 - val_head_r2: 0.0285 - val_loss: 1.2083 - learning_rate: 1.8246e-05\nEpoch 32/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 792ms/step - head_r2: 0.0902 - loss: 1.0676 - val_head_r2: 0.0246 - val_loss: 1.2127 - learning_rate: 1.3684e-05\nEpoch 33/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 795ms/step - head_r2: 0.0885 - loss: 1.0685 - val_head_r2: 0.0261 - val_loss: 1.2118 - learning_rate: 1.3684e-05\nEpoch 34/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 791ms/step - head_r2: 0.0950 - loss: 1.0629 - val_head_r2: 0.0247 - val_loss: 1.2141 - learning_rate: 1.0263e-05\nEpoch 35/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 808ms/step - head_r2: 0.0900 - loss: 1.0641 - val_head_r2: 0.0230 - val_loss: 1.2148 - learning_rate: 1.0263e-05\nEpoch 36/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 809ms/step - head_r2: 0.0935 - loss: 1.0632 - val_head_r2: 0.0210 - val_loss: 1.2175 - learning_rate: 7.6974e-06\nEpoch 37/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 804ms/step - head_r2: 0.0939 - loss: 1.0602 - val_head_r2: 0.0194 - val_loss: 1.2197 - learning_rate: 7.6974e-06\nEpoch 38/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 801ms/step - head_r2: 0.0945 - loss: 1.0602 - val_head_r2: 0.0209 - val_loss: 1.2187 - learning_rate: 5.7730e-06\nEpoch 39/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 807ms/step - head_r2: 0.0971 - loss: 1.0566 - val_head_r2: 0.0212 - val_loss: 1.2182 - learning_rate: 5.7730e-06\nEpoch 40/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 809ms/step - head_r2: 0.0969 - loss: 1.0571 - val_head_r2: 0.0198 - val_loss: 1.2196 - learning_rate: 4.3298e-06\nEpoch 41/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 810ms/step - head_r2: 0.0977 - loss: 1.0535 - val_head_r2: 0.0204 - val_loss: 1.2188 - learning_rate: 4.3298e-06\nEpoch 42/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 812ms/step - head_r2: 0.0995 - loss: 1.0533 - val_head_r2: 0.0206 - val_loss: 1.2189 - learning_rate: 3.2473e-06\nEpoch 43/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 793ms/step - head_r2: 0.1000 - loss: 1.0543 - val_head_r2: 0.0199 - val_loss: 1.2194 - learning_rate: 3.2473e-06\nEpoch 44/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 842ms/step - head_r2: 0.1027 - loss: 1.0478 - val_head_r2: 0.0200 - val_loss: 1.2197 - learning_rate: 2.4355e-06\nEpoch 45/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 816ms/step - head_r2: 0.0990 - loss: 1.0544 - val_head_r2: 0.0202 - val_loss: 1.2192 - learning_rate: 2.4355e-06\nEpoch 46/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 813ms/step - head_r2: 0.1002 - loss: 1.0528 - val_head_r2: 0.0201 - val_loss: 1.2199 - learning_rate: 1.8266e-06\nEpoch 47/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 810ms/step - head_r2: 0.0998 - loss: 1.0532 - val_head_r2: 0.0204 - val_loss: 1.2195 - learning_rate: 1.8266e-06\nEpoch 48/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 817ms/step - head_r2: 0.1027 - loss: 1.0491 - val_head_r2: 0.0196 - val_loss: 1.2207 - learning_rate: 1.3700e-06\nEpoch 49/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 818ms/step - head_r2: 0.1015 - loss: 1.0495 - val_head_r2: 0.0200 - val_loss: 1.2202 - learning_rate: 1.3700e-06\nEpoch 50/50\n\u001b[1m462/462\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 793ms/step - head_r2: 0.1005 - loss: 1.0568 - val_head_r2: 0.0195 - val_loss: 1.2205 - learning_rate: 1.0275e-06\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ğŸ“‹ | Result","metadata":{}},{"cell_type":"code","source":"# Best Result\nbest_R2 = max(history.history['val_head_r2'])\nbest_Epoch = np.argmax(history.history['val_head_r2']) + 1\nprint(\"#\" * 10 + \" Result \" + \"#\" * 10)\nprint(f\"Best R2: {best_R2:.5f}\")\nprint(f\"Best Epoch: {best_Epoch}\")\nprint(\"#\" * 28)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T15:43:55.678207Z","iopub.execute_input":"2024-03-29T15:43:55.678595Z","iopub.status.idle":"2024-03-29T15:43:55.685884Z","shell.execute_reply.started":"2024-03-29T15:43:55.678562Z","shell.execute_reply":"2024-03-29T15:43:55.684717Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"########## Result ##########\nBest R2: 0.05204\nBest Epoch: 14\n############################\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ğŸ§ª | Prediction","metadata":{}},{"cell_type":"markdown","source":"## Load Best Model","metadata":{}},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2024-03-28T21:14:10.079124Z","iopub.execute_input":"2024-03-28T21:14:10.080106Z","iopub.status.idle":"2024-03-28T21:14:11.192716Z","shell.execute_reply.started":"2024-03-28T21:14:10.080066Z","shell.execute_reply":"2024-03-28T21:14:11.191436Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-03-28T21:14:01.903568Z","iopub.execute_input":"2024-03-28T21:14:01.904250Z","iopub.status.idle":"2024-03-28T21:14:03.029627Z","shell.execute_reply.started":"2024-03-28T21:14:01.904216Z","shell.execute_reply":"2024-03-28T21:14:03.028464Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"best_model.keras  model.png  submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_weights(\"best_model.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-03-29T15:44:06.652741Z","iopub.execute_input":"2024-03-29T15:44:06.653109Z","iopub.status.idle":"2024-03-29T15:44:07.499468Z","shell.execute_reply.started":"2024-03-29T15:44:06.653081Z","shell.execute_reply":"2024-03-29T15:44:07.498000Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Build Test Dataset\n\nDon't forget to normalize for the test data as well.","metadata":{}},{"cell_type":"code","source":"# Test\ntest_paths = test_df.image_path.values\ntest_features = scaler.transform(test_df[FEATURE_COLS].values) \ntest_ds = build_dataset(test_paths, test_features, batch_size=CFG.batch_size,\n                         repeat=False, shuffle=False, augment=False, cache=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T15:44:08.337648Z","iopub.execute_input":"2024-03-29T15:44:08.338048Z","iopub.status.idle":"2024-03-29T15:44:08.403321Z","shell.execute_reply.started":"2024-03-29T15:44:08.338018Z","shell.execute_reply":"2024-03-29T15:44:08.402266Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n\nAs our model outputs predictions for two tasks and our submission requires only one, we will take predictions from the main task (`head`) and ignore predictions from the auxiliary task.","metadata":{}},{"cell_type":"code","source":"preds = model.predict(test_ds)[\"head\"]","metadata":{"execution":{"iopub.status.busy":"2024-03-29T15:44:10.152663Z","iopub.execute_input":"2024-03-29T15:44:10.153052Z","iopub.status.idle":"2024-03-29T15:44:31.853277Z","shell.execute_reply.started":"2024-03-29T15:44:10.153022Z","shell.execute_reply":"2024-03-29T15:44:31.852200Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 275ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ğŸ“© | Submission","metadata":{}},{"cell_type":"code","source":"pred_df = test_df[[\"id\"]].copy()\ntarget_cols = [x.replace(\"_mean\",\"\") for x in CFG.class_names]\npred_df[target_cols] = preds.tolist()\n\nsub_df = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\nsub_df = sub_df[[\"id\"]].copy()\nsub_df = sub_df.merge(pred_df, on=\"id\", how=\"left\")\nsub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T15:44:31.854917Z","iopub.execute_input":"2024-03-29T15:44:31.855189Z","iopub.status.idle":"2024-03-29T15:44:31.908155Z","shell.execute_reply.started":"2024-03-29T15:44:31.855166Z","shell.execute_reply":"2024-03-29T15:44:31.907177Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"          id        X4       X11       X18       X26       X50       X3112\n0  201238668 -0.275330  0.483565 -0.163461  0.248401 -0.239704   69.892166\n1  202310319 -0.292679  0.252194 -0.265848 -0.252753 -0.264543   64.487892\n2  202604412 -0.488152 -0.421938 -0.383850  0.151822 -0.449667    9.455019\n3  201353439 -0.120251  1.210081 -0.007531 -0.149555 -0.077549  110.090080\n4  195351745 -0.176650  0.303893 -0.321399 -0.373532 -0.154102   24.426065","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>X4</th>\n      <th>X11</th>\n      <th>X18</th>\n      <th>X26</th>\n      <th>X50</th>\n      <th>X3112</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201238668</td>\n      <td>-0.275330</td>\n      <td>0.483565</td>\n      <td>-0.163461</td>\n      <td>0.248401</td>\n      <td>-0.239704</td>\n      <td>69.892166</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>202310319</td>\n      <td>-0.292679</td>\n      <td>0.252194</td>\n      <td>-0.265848</td>\n      <td>-0.252753</td>\n      <td>-0.264543</td>\n      <td>64.487892</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>202604412</td>\n      <td>-0.488152</td>\n      <td>-0.421938</td>\n      <td>-0.383850</td>\n      <td>0.151822</td>\n      <td>-0.449667</td>\n      <td>9.455019</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>201353439</td>\n      <td>-0.120251</td>\n      <td>1.210081</td>\n      <td>-0.007531</td>\n      <td>-0.149555</td>\n      <td>-0.077549</td>\n      <td>110.090080</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>195351745</td>\n      <td>-0.176650</td>\n      <td>0.303893</td>\n      <td>-0.321399</td>\n      <td>-0.373532</td>\n      <td>-0.154102</td>\n      <td>24.426065</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}